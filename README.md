# Controllable Text Generation
* [Plug and Play Language Models: A Simple Approach to Controlled Text Generation](https://arxiv.org/pdf/1912.02164.pdf)
  * Guide text generation with one or more simple attribute classifiers
  * A three steps approach: forward, backward with respect to evaluation result from the classifier, forward
* [Side-Tuning: A Baseline for Network Adaptation via Additive Side Networks](https://arxiv.org/pdf/1912.13503.pdf)
* [Technical Report: Auxiliary Tuning and its Application to Conditional Text Generation](https://arxiv.org/pdf/2006.16823.pdf)
* [GeDi: Generative Discriminator Guided Sequence Generation](https://arxiv.org/pdf/2009.06367.pdf)
* [Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/abs/2101.00190)
  * Only tuning the prefix vector works well on downstream tasks 
* [GPT Understands, Too](https://arxiv.org/abs/2103.10385)
* [The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/abs/2104.08691)
* [Back to the Future: Unsupervised Backprop-based Decoding for Counterfactual and Abductive Commonsense Reasoning](https://aclanthology.org/2020.emnlp-main.58.pdf)
